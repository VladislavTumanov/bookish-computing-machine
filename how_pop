import numpy as np
import pandas as pd
import requests
import io 
import seaborn as sns
import torch 
from matplotlib import pyplot as plt
import random
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_score, recall_score, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import Ridge
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from IPython.display import display
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error
from sklearn.feature_extraction import DictVectorizer
import scipy
from sklearn.model_selection import  StratifiedKFold
from sklearn.ensemble import BaggingClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.linear_model import Lasso, LassoCV, LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics
from sklearn.cluster import AgglomerativeClustering, KMeans, SpectralClustering
from sklearn.decomposition import PCA
from sklearn.metrics.cluster import adjusted_rand_score
from tqdm import tqdm
from sklearn.base import BaseEstimator
from sklearn.metrics import mean_squared_error, log_loss, roc_auc_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

from google.colab import files
uploaded = files.upload()
train_df = pd.read_csv(io.BytesIO(uploaded['howpop_train.csv']))

train_df = pd.read_csv(io.BytesIO(uploaded['howpop_train.csv']))

from google.colab import files
uploaded = files.upload()

test_df = pd.read_csv(io.BytesIO(uploaded['howpop_test.csv']))

from pandas.core.tools.datetimes import to_datetime
train_df['published'].apply(lambda ts: pd.to_datetime(ts).value).plot() 
# sort by published

fig, ax = plt.subplots(figsize=(12, 8))
sns.heatmap(train_df.corr(), annot = True, ax = ax) 
#there are no too high correlation values (max = 0.69)

train_df['published'].value_counts()
Year_ = pd.DatetimeIndex(train_df['published']).year
Year_.value_counts() # most of all the publication in 2015 year

feature = ['author', 'flow', 'domain','title']
train_size = int(0.7 * train_df.shape[0])

X, y = train_df.loc[: , feature], train_df['favs_lognorm']
X_test = test_df.loc[:, feature]
X_train, X_valid = X.iloc[:train_size , :], X.iloc[train_size :, :]
y_train, y_valid = y.iloc[:train_size], y.iloc[train_size:]

vectorizer_title = TfidfVectorizer(min_df=3, max_df=0.3, ngram_range=(1, 3))
X_train_title = vectorizer_title.fit_transform(X_train['title'])
X_test_title = vectorizer_title.transform(X_test['title'])
X_valid_title =vectorizer_title.transform(X_valid['title'])
vectorizer_title.vocabulary_['python']

vectorizer_title_ch = TfidfVectorizer(min_df=3, max_df=0.3, ngram_range=(1, 3), analyzer='char')
X_train_title_ch = vectorizer_title.fit_transform(X_train['title'])
X_test_title_ch = vectorizer_title.transform(X_test['title'])
X_valid_title_ch =vectorizer_title.transform(X_valid['title'])

vectorizer_title = TfidfVectorizer(analyzer='char')
X_train_title = vectorizer_title.fit_transform(X_train['title'])
X_test_title = vectorizer_title.transform(X_test['title'])
X_valid_title =vectorizer_title.transform(X_valid['title'])

feats = ['author', 'flow', 'domain']
X_train[feats][:5].fillna('-').T.to_dict()

dict_vect = DictVectorizer()
dict_vect_matrix = dict_vect.fit_transform(X_train[feats][:5].fillna('-').T.to_dict().values())
dict_vect_matrix

dict_vect_matrix.toarray()

feats = ['author', 'flow', 'domain']
vectorizer_feats = DictVectorizer()
X_train_feats = vectorizer_feats.fit_transform(X_train[feats].fillna('-').T.to_dict().values())
X_valid_feats = vectorizer_feats.fit_transform(X_valid[feats].fillna('-').T.to_dict().values())
X_test_feats = vectorizer_feats.fit_transform(X_test[feats].fillna('-').T.to_dict().values())

X_train_new = scipy.sparse.hstack([X_train_feats, X_train_title_ch, X_train_title])
X_valid_new = scipy.sparse.hstack([X_valid_feats, X_valid_title_ch, X_valid_title])
X_test_new = scipy.sparse.hstack([X_test_feats, X_test_title_ch, X_test_title])

model = Ridge()
model.fit(scipy.sparse.vstack([X_train_new, X_valid_new]), y) 
test_preds = model.predict(X_test_new)

sample_submission.head()
